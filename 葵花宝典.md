# 1、消息队列

## 01、为什么要用消息队列

&ensp;&ensp;&ensp;&ensp;当有些交易结果不是实时返回，或者采用异步返回的时候，我们会将这笔支付的支付结果发送给上游系统，为了在dubbo服务调用产生循环依赖的问题， 所以采用了消息队列， （也可以使用http的方式）。

&ensp;&ensp;&ensp;&ensp;场景：（异步、解耦、削峰）

- 交易异步返回，结果不明确，采用消息队列或者比较耗时的操作使用kafka通知(异步 提升性能)
- 配置信息更新，由于不同模块间的redis库不同，需要发送消息更新缓存信息
- 消息队列可以将高并发任务存储到队列中，削弱高并发峰值(适用于跑批任务）
- 多个系统需要A系统的实时数据，此时A系统可以将数据写到消息队列，其他系统去拉取数据（解耦）

&ensp;&ensp;&ensp;&ensp;生产案例

案例1：生产批付业务

&ensp;&ensp;&ensp;&ensp;结算系统每日整点发起批量扣款（通过dubbo接口）业务到账务平台，由于扣款业务涉及到操作数据库和多个业务处理，比较耗时，无法使用同步返回数据结果，所以当批扣调用扣款接口时 ，全部返回受理成功，账务平台的入账操作全部改为异步处理，入账操作完成而且订单信息更新完成则发送异步消息到结算系统，当结算系统收到账务平台推送过来大批量消息时，结算系统根据自身平台处理并发能力，每次拉去100个消息进行消费，其余消息继续留在消息队列缓存中，等处理完再次拉取，不至于大量的并发一起到来导致结算平台无法正常工作，达到削峰的目的 。

案例2：热点消息推送

&ensp;&ensp;&ensp;&ensp;营销平台有新的优惠信息时，会将信息推送到每个用户的手机，信息推送使用了kafka消息队列， 营销平台将优惠信息推送至kafka的topic，消费者为客户端平台，客户端每次会从指定的topic拉取消息，推送给用户，但是由于当时消息offset提交机制使用了自动提交，经常会重复推送相同的消息到用户手机，用户体验不好，后来使用了ack=record，每条消息都确认，这样可以在稍微牺牲一点新跟那个的条件下，提高用户体验，而且消息也不会丢失。

## 02、消息队列的优缺点

### 优点

&ensp;&ensp;&ensp;&ensp;异步、解耦、削峰

### 缺点

- 系统可用性降低，增加一层中间件，如果中间件挂掉会导致业务无法正常进行

- 系统复杂度增加，需要考虑消息队列的可用性，重复消费，消息丢失等问题

- 一致性问题，当某个功能由多个系统功能决定时，使用消息队列有一个系统失败，整个功能都应该是失败的。消息队列无法做到这点。

  

### 技术选型

activeMq: 万级并发，功能完善，消息偶尔丢失 社区活跃度不高 不建议使用

rabbitMq:万级并发，社区活跃 使用erlang开发 响应时间极短 微秒级别，管理界面很棒，如果业务量不是太大可以使用 

rocketMq: 十万级别并发，阿里开源 分布式架构  topic增多 不怎么影响性能 数据量大的建议使用

kafka:十万级并发，功能不多，适用于大数据方面，但是随着topic增多，性能有较大影响，在大数据统计，日志搜集方面使用。

## 03、如何保证消息队列的高可用

## &ensp;&ensp;&ensp;&ensp;rocketMq集群

&ensp;&ensp;&ensp;&ensp;rocketMq是使用Name Server集群，集群中使用多主多从，没有选举机制。

![](C:\Users\ljp\Desktop\mds\面试\消息队列\rmq-basic-arc.png)

&ensp;&ensp;&ensp;&ensp;集群工作过程

- Producer连接到Name Server集群中的一个Master，并保持长连接，定时向Broker发送心跳，并将消息发送到Broker

- ## Consumer连接到Name Server提供某个Topic服务的所有Master和Slave，并保持长连接，从Master和Slave订阅消息

## &ensp;&ensp;&ensp;&ensp;kafak集群

![](C:\Users\ljp\Desktop\mds\面试\消息队列\consumer-groups.png)

kafka集群是使用zookeeper作为注册中心管理Broker集群节点的。

kafka集群工作过程

- kafka将消息存储在topic上，为了扩展一个topic允许放到不同的partition上，partition可以分布在不同的Broker上

- kafka通过zk选举leader，以及consumer组发生变化时 还会发生rebalance，消息消费记录使用offset标记，允许有多个consumer组，每个组消费消息的offset不受干扰

- producer通过push消息到broker，consumer通过pull 消费消息

## &ensp;&ensp;&ensp;&ensp;Rabbit集群

### &ensp;&ensp;&ensp;&ensp;普通模式

​    对于Queue来说，消息实体只存在于其中一个节点rabbit01（或者rabbit02），rabbit01和rabbit02两个节点仅有相同的元数据，即队列的结构。当消息进入rabbit01节点的Queue后，consumer从rabbit02节点消费时，RabbitMQ会临时在rabbit01、rabbit02间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。当rabbit01节点故障后，rabbit02节点无法取到rabbit01节点中还未消费的消息实体。如果做了消息持久化，那么得等rabbit01节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。

### &ensp;&ensp;&ensp;&ensp;镜像模式

​       把需要的队列做成镜像队列，存在与多个节点属于**RabbitMQ的HA方案。**该模式解决了普通模式中的问题，其实质和普通模式不同之处在于，消息实体会主动在镜像节点间同步，而不是在客户端取数据时临时拉取。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。所以在对可靠性要求较高的场合中适用。

  

## 04、如何解决消息的重复消费问题（幂等性）

###  问题产生场景

&ensp;&ensp;&ensp;&ensp;消息的重复消费一般是由消费者消费过的消息后， 针对这条消息消费的确认信息并没有发送到broker服务上（可能由于网络原因），broker还认为这条消息未被消费，产生重复消费的问题，rocketMq发送消息确认的信息是通过ACK确认的方式，kafka是通过提交offset实现的。

### 问题解决

消息的重复消费解决方案，要根据具体场景来处理

- 当要执行的是幂等操作时候，无需处理，每次消费的结果是一致的。（比如 更新交易状态，如果第一次消息通知修改未终态的交易为终态，第二次再来消费同样的信息时发现该笔交易状态已是终态，无需更该即可。）
- 当要执行的操作不是幂等操作，每次执行结果都不一样，只能借助第三方数据存储，比如借助于redis等内存数据库，将消费过的消息以key-value的形式保存下来并且设置一个失效时间，每次有新的消息过来的时候先去redis查看消息是否被消费过。（当业务是一个评论功能的时候，有新评论发布就需要把数据新增到数据库并展示给用户，这个过程允许多次insert，所以就要校验数据是否已经被消费过）

## 04、如何保证消息的可靠性传输

要保证消息的可靠性传输，其实也就是要保证消息在生产环境中不丢失，分析这个问题可以从三个方面分析:

- 生产者生产不丢失

- 消息队列存储不丢失

- 消费者消费不丢失

&ensp;&ensp;&ensp;&ensp;由于我们生产用的是kafka，所以这里以kafak为例进行分析

![](C:\Users\ljp\Desktop\mds\面试\消息队列\kafak消费消息数据流.png)

&ensp;&ensp;&ensp;&ensp;kafka生产者生产消息在集群中的流转分析

&ensp;&ensp;&ensp;&ensp;当producer生产消息发布到某个partation时先通过zk找到partation的leader，然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica）只将消息写入到leader，leader将消息写入到本地的log，flower从leader拉取leader的消息同步

（1）生产者丢数据

- 在producer端配置ack=all，当partation所有的flower都写入成功后，才把这条消息当作写入成功。
- 在producer设置重试次数，retries=MAX，当消息写入失败后会无限重试写入，生产最调大这个参数即可。 

（2）消息队列丢数据

&ensp;&ensp;&ensp;&ensp;消息队列丢数据的情况发生在，leader突然暴毙，然后flower没有拉取到leader的最新数据，导致消息队列的数据丢失

- replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本
- min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系

（3）消费者丢数据

&ensp;&ensp;&ensp;&ensp;消费者丢数据是因为消费者还没有消费完数据，系统就自动提交了offset，此时如果消费者消费消息的时候发生异常，这条消息其实并未准确处理，但由于自动提交，kafak已经将该消费组消费的topic的partation的当前offset往后移动，此条消息已被当作处理过，导致数据丢失问题，解决这个问题的方式就是使用自动提交+手动提交的方式提交消息的offset

Rabbit 消息不丢失：

生产者丢消息:

1、使用事务机制（耗费性能，不常用）

2、使用confirm，生产者发送消息后，如果成功会回调生产者接口告知消息发送成功，失败也会调用接口告知发送失败

Rabbit自身丢数据：

1、创建queue设置为持久化，可以设置queue元数据是持久化的，但不会持久化queue里面的数据。

2、发送消息时将消息的deliveryMode设置为2，就是将消息设置为持久化，此时rabbitMq就会将消息持久化到磁盘

必须同时进行这两个数据才可以。   

消费者丢数据：

消费者弄丢数据：

1、消费端开启了autoAck,自动提交，导致消费者可能并未完成消费，就自动提交了消费已经被消费掉的信息

2、解决办法是关闭自动提交，进行手动提交

## 05、如何保证消息的顺序

 Rabbit：

在queue中的数据消费是有序的，所以如果有多个消费者，就为每个消费者创建一个queue，没从达到有序消费的目的。

kafka：

首先kafka的partation的数据肯定是有顺序的，而且一个消费者只能对应一个partation，但kafka一个消费者可能会有多个线程消费，所以就会导致消费的数据无序，这种情况，需要对数据的key进行hash算法，放入到指定的内存队列，比如数据消费顺序是A_info，B_info,C_info。此时需要将数据先分别保存到队列A,B,C中，当线程消费时，就按顺序从A,B,C队列拿到A_info，B_info,C_info数据进行顺序消费。 

## 06、mq积压了大量的数据

- 由于消费者挂掉，mq挤压大量数据，如果恢复消费者，快速消费挤压数据

  如果生产上由于消费者挂掉导致队列里积压了上千万数据，如果是kafka消息，由于topic的分区数已经指定，机器扩容无法解决实质问题，只能将消息重新写入一个临时topic，然后topic分成几十个分区，由几十个消费者快速消费消息。

- mq积压大量数据，导致mq磁盘满

  

- rabbitMq 设置过期时间 由于数据太大来不及消费，一些数据过期丢失 如何解决

  由于设置了过期时间，消息无法恢复，只能手动通过跑程序补消息

## 07、如何设计一个消息中间件

# 2、Elasticsearch

## 01、es分布式原理

### es数据基本数据结构

​     es的基本数据结构是由index-->type--> mapping-->document-->file 组成。index相当于一大类的数据集合，type是这堆数据中具有相似结构的一堆数据，mapping 是 type 结构的定义，定义了type的字段和类型。往type里写的一条数据就是一个document，  filed就是docment一个字段的值。

### es分布式存储

​      es会将一个index分成多个shard存储到不同的机器上，每个shard都会有一个primary shard 和多个 replica shard，primary shard负责写入数据并将数据同步到replica shard 上。 replica shard 不能写入数据，但是允许读数据，减缓primary shard的压力。当primary shard 宕机后，会从replica shard 中选择一个成为primary shard 使其达到高可用。

## 02、es写入数据的原理

数据写入



数据删除

搜索数据

## 03、es查询数据原理

## 04、es再数据量很大情况下（数十亿）如何提高查询性能

filesystem cache

1、filesystem cache的容量最好为系统存储的数据的一半

2、往es中存储一条数据中只用于检索的数据，filesystem cache会缓存更多的数据，其余整条数据放入数据库，比如只存储一行数据的id，name price 等关键信息，其余几十个产品属性放入到数据库中,使用es+mysq的方式

缓存预热

冷热拆分

document设计

分页性能优化

## 05、es生产集群的部署架构

## 