# 1、消息队列

## 01、为什么要用消息队列

&ensp;&ensp;&ensp;&ensp;当有些交易结果不是实时返回，或者采用异步返回的时候，我们会将这笔支付的支付结果发送给上游系统，为了在dubbo服务调用产生循环依赖的问题， 所以采用了消息队列， （也可以使用http的方式）。

&ensp;&ensp;&ensp;&ensp;场景：（异步、解耦、削峰）

- 交易异步返回，结果不明确，采用消息队列。
- 配置信息更新，由于不同模块间的redis库不同，需要发送消息更新缓存信息
- 消息队列可以将高并发任务存储到队列中，削弱高并发峰值(适用于跑批任务)

## 02、消息队列的优缺点

### 优点

&ensp;&ensp;&ensp;&ensp;异步、解耦、削峰

### 缺点

- 系统可用性降低，增加一层中间件，如果中间价挂掉会导致业务无法正常进行
- 系统复杂度增加，需要考虑消息队列的可用性，重复消费，消息丢失等问题

## 03、如何保证消息队列的高可用

## &ensp;&ensp;&ensp;&ensp;rocketMq集群

&ensp;&ensp;&ensp;&ensp;rocketMq是使用Name Server集群，集群中使用多主多从，没有选举机制。

![](C:\Users\ljp\Desktop\mds\面试\消息队列\rmq-basic-arc.png)

&ensp;&ensp;&ensp;&ensp;集群工作过程

- Producer连接到Name Server集群中的一个Master，并保持长连接，定时向Broker发送心跳，并将消息发送到Broker

- Consumer连接到Name Server提供某个Topic服务的所有Master和Slave，并保持长连接，从Master和Slave订阅消息

## &ensp;&ensp;&ensp;&ensp;kafak集群

![](C:\Users\ljp\Desktop\mds\面试\消息队列\consumer-groups.png)

kafka集群是使用zookeeper作为注册中心管理Broker集群节点的。

kafka集群工作过程

- kafka将消息存储在topic上，为了扩展一个topic允许放到不同的partition上，partition可以分布在不同的Broker上
- kafka通过zk选举leader，以及consumer组发生变化时 还会发生rebalance，消息消费记录使用offset标记，允许有多个consumer组，每个组消费消息的offset不受干扰
- producer通过push消息到broker，consumer通过pull 消费消息

## 04、如何解决消息的重复消费问题

###  问题产生场景

&ensp;&ensp;&ensp;&ensp;消息的重复消费一般是由消费者消费过的消息后， 针对这条消息消费的确认信息并没有发送到broker服务上（可能由于网络原因），broker还认为这条消息未被消费，产生重复消费的问题，rocketMq发送消息确认的信息是通过ACS确认的方式，kafka是通过提交offset实现的。

### 问题解决

消息的重复消费解决方案，要根据具体场景来处理

- 当要执行的是幂等操作时候，无需处理，每次消费的结果是一致的。（比如 更新交易状态，如果第一次消息通知修改未终态的交易为终态，第二次再来消费同样的信息时发现该笔交易状态已是终态，无需更该即可。）
- 当要执行的操作不是幂等操作，每次执行结果都不一样，只能借助第三方数据存储，比如借助于redis等内存数据库，将消费过的消息以key-value的形式保存下来并且设置一个失效时间，每次有新的消息过来的时候先去redis查看消息是否被消费过。（当业务是一个评论功能的时候，有新评论发布就需要把数据新增到数据库并展示给用户，这个过程允许多次insert，所以就要校验数据是否已经被消费过）

## 04、如何保证消息的可靠性传输

要保证消息的可靠性传输，其实也就是要保证消息在生产环境中不丢失，分析这个问题可以从三个方面分析:

- 生产者生产不丢失

- 消息队列存储不丢失

- 消费者消费不丢失

&ensp;&ensp;&ensp;&ensp;由于我们生产用的是kafka，所以这里以kafak为例进行分析

![](C:\Users\ljp\Desktop\mds\面试\消息队列\kafak消费消息数据流.png)

&ensp;&ensp;&ensp;&ensp;kafka生产者生产消息在集群中的流转分析

&ensp;&ensp;&ensp;&ensp;当producer生产消息发布到某个partation时先通过zk找到partation的leader，然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica）只将消息写入到leader，leader将消息写入到本地的log，flower从leader拉取leader的消息同步

（1）生产者丢数据

- 在producer端配置ack=all，当partation所有的flower都写入成功后，才把这条消息当作写入成功。
- 在producer设置重试次数，retries=MAX，当消息写入失败后会无限重试写入，生产最调大这个参数即可。 

（2）消息队列丢数据

&ensp;&ensp;&ensp;&ensp;消息队列丢数据的情况发生在，leader突然暴毙，然后flower没有拉取到leader的最新数据，导致消息队列的数据丢失

- replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本
- min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系

（3）消费者丢数据

&ensp;&ensp;&ensp;&ensp;消费者丢数据是因为消费者还没有消费完数据，系统就自动提交了offset，此时如果消费者消费消息的时候发生异常，这条消息其实并未准确处理，但由于自动提交，kafak已经将该消费组消费的topic的partation的当前offset往后移动，此条消息已被当作处理过，导致数据丢失问题，解决这个问题的方式就是使用自动提交+手动提交的方式提交消息的offset

## 05、如何保证消息的顺序

## 06、mq挤压了大量的数据

- 由于消费者挂掉，mq挤压大量数据，如果恢复消费者，快速消费挤压数据
- mq积压大量数据，导致mq磁盘满
- rabbitMq 设置过期时间 由于数据太大来不及消费，一些数据过期丢失 如何解决

