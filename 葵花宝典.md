# 1、消息队列

## 01、为什么要用消息队列

&ensp;&ensp;&ensp;&ensp;当有些交易结果不是实时返回，或者采用异步返回的时候，我们会将这笔支付的支付结果发送给上游系统，为了在dubbo服务调用产生循环依赖的问题， 所以采用了消息队列， （也可以使用http的方式）。

&ensp;&ensp;&ensp;&ensp;场景：（异步、解耦、削峰）

- 交易异步返回，结果不明确，采用消息队列或者比较耗时的操作使用kafka通知(异步 提升性能)
- 配置信息更新，由于不同模块间的redis库不同，需要发送消息更新缓存信息
- 消息队列可以将高并发任务存储到队列中，削弱高并发峰值(适用于跑批任务）
- 多个系统需要A系统的实时数据，此时A系统可以将数据写到消息队列，其他系统去拉取数据（解耦）

&ensp;&ensp;&ensp;&ensp;生产案例

案例1：生产批付业务

&ensp;&ensp;&ensp;&ensp;结算系统每日整点发起批量扣款（通过dubbo接口）业务到账务平台，由于扣款业务涉及到操作数据库和多个业务处理，比较耗时，无法使用同步返回数据结果，所以当批扣调用扣款接口时 ，全部返回受理成功，账务平台的入账操作全部改为异步处理，入账操作完成而且订单信息更新完成则发送异步消息到结算系统，当结算系统收到账务平台推送过来大批量消息时，结算系统根据自身平台处理并发能力，每次拉去100个消息进行消费，其余消息继续留在消息队列缓存中，等处理完再次拉取，不至于大量的并发一起到来导致结算平台无法正常工作，达到削峰的目的 。

案例2：热点消息推送

&ensp;&ensp;&ensp;&ensp;营销平台有新的优惠信息时，会将信息推送到每个用户的手机，信息推送使用了kafka消息队列， 营销平台将优惠信息推送至kafka的topic，消费者为客户端平台，客户端每次会从指定的topic拉取消息，推送给用户，但是由于当时消息offset提交机制使用了自动提交，经常会重复推送相同的消息到用户手机，用户体验不好，后来使用了ack=record，每条消息都确认，这样可以在稍微牺牲一点新跟那个的条件下，提高用户体验，而且消息也不会丢失。

## 02、消息队列的优缺点

### 优点

&ensp;&ensp;&ensp;&ensp;异步、解耦、削峰

### 缺点

- 系统可用性降低，增加一层中间件，如果中间件挂掉会导致业务无法正常进行

- 系统复杂度增加，需要考虑消息队列的可用性，重复消费，消息丢失等问题

- 一致性问题，当某个功能由多个系统功能决定时，使用消息队列有一个系统失败，整个功能都应该是失败的。消息队列无法做到这点。

  

## 03、技术选型

activeMq: 万级并发，功能完善，消息偶尔丢失 社区活跃度不高 不建议使用

rabbitMq:万级并发，社区活跃 使用erlang开发 响应时间极短 微秒级别，管理界面很棒，如果业务量不是太大可以使用 

rocketMq: 十万级别并发，阿里开源 分布式架构  topic增多 不怎么影响性能 数据量大的建议使用

kafka:十万级并发，功能不多，适用于大数据方面，但是随着topic增多，性能有较大影响，在大数据统计，日志搜集方面使用。

## 03、如何保证消息队列的高可用

## &ensp;&ensp;&ensp;&ensp;rocketMq集群

&ensp;&ensp;&ensp;&ensp;rocketMq是使用Name Server集群，集群中使用多主多从，没有选举机制。

![](C:\Users\ljp\Desktop\mds\面试\消息队列\rmq-basic-arc.png)

&ensp;&ensp;&ensp;&ensp;集群工作过程

- Producer连接到Name Server集群中的一个Master，并保持长连接，定时向Broker发送心跳，并将消息发送到Broker

- Consumer连接到Name Server提供某个Topic服务的所有Master和Slave，并保持长连接，从Master和Slave订阅消息

## &ensp;&ensp;&ensp;&ensp;kafak集群

![](C:\Users\ljp\Desktop\mds\面试\消息队列\consumer-groups.png)

kafka集群是使用zookeeper作为注册中心管理Broker集群节点的。

kafka集群工作过程

- kafka将消息存储在topic上，为了扩展一个topic允许放到不同的partition上，partition可以分布在不同的Broker上
- kafka通过zk选举leader，以及consumer组发生变化时 还会发生rebalance，消息消费记录使用offset标记，允许有多个consumer组，每个组消费消息的offset不受干扰
- producer通过push消息到broker，consumer通过pull 消费消息

## 04、如何解决消息的重复消费问题（幂等性）

###  问题产生场景

&ensp;&ensp;&ensp;&ensp;消息的重复消费一般是由消费者消费过的消息后， 针对这条消息消费的确认信息并没有发送到broker服务上（可能由于网络原因），broker还认为这条消息未被消费，产生重复消费的问题，rocketMq发送消息确认的信息是通过ACK确认的方式，kafka是通过提交offset实现的。

### 问题解决

消息的重复消费解决方案，要根据具体场景来处理

- 当要执行的是幂等操作时候，无需处理，每次消费的结果是一致的。（比如 更新交易状态，如果第一次消息通知修改未终态的交易为终态，第二次再来消费同样的信息时发现该笔交易状态已是终态，无需更该即可。）
- 当要执行的操作不是幂等操作，每次执行结果都不一样，只能借助第三方数据存储，比如借助于redis等内存数据库，将消费过的消息以key-value的形式保存下来并且设置一个失效时间，每次有新的消息过来的时候先去redis查看消息是否被消费过。（当业务是一个评论功能的时候，有新评论发布就需要把数据新增到数据库并展示给用户，这个过程允许多次insert，所以就要校验数据是否已经被消费过）

## 04、如何保证消息的可靠性传输

要保证消息的可靠性传输，其实也就是要保证消息在生产环境中不丢失，分析这个问题可以从三个方面分析:

- 生产者生产不丢失

- 消息队列存储不丢失

- 消费者消费不丢失

&ensp;&ensp;&ensp;&ensp;由于我们生产用的是kafka，所以这里以kafak为例进行分析

![](C:\Users\ljp\Desktop\mds\面试\消息队列\kafak消费消息数据流.png)

&ensp;&ensp;&ensp;&ensp;kafka生产者生产消息在集群中的流转分析

&ensp;&ensp;&ensp;&ensp;当producer生产消息发布到某个partation时先通过zk找到partation的leader，然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica）只将消息写入到leader，leader将消息写入到本地的log，flower从leader拉取leader的消息同步

（1）生产者丢数据

- 在producer端配置ack=all，当partation所有的flower都写入成功后，才把这条消息当作写入成功。
- 在producer设置重试次数，retries=MAX，当消息写入失败后会无限重试写入，生产最调大这个参数即可。 

（2）消息队列丢数据

&ensp;&ensp;&ensp;&ensp;消息队列丢数据的情况发生在，leader突然暴毙，然后flower没有拉取到leader的最新数据，导致消息队列的数据丢失

- replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本
- min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系

（3）消费者丢数据

&ensp;&ensp;&ensp;&ensp;消费者丢数据是因为消费者还没有消费完数据，系统就自动提交了offset，此时如果消费者消费消息的时候发生异常，这条消息其实并未准确处理，但由于自动提交，kafak已经将该消费组消费的topic的partation的当前offset往后移动，此条消息已被当作处理过，导致数据丢失问题，解决这个问题的方式就是使用自动提交+手动提交的方式提交消息的offset

Rabbit 消息不丢失：

生产者丢消息:

1、使用事务机制（耗费性能，不常用）

2、使用confirm，生产者发送消息后，如果成功会回调生产者接口告知消息发送成功，失败也会调用接口告知发送失败

Rabbit自身丢数据：

1、创建queue设置为持久化，可以设置queue元数据是持久化的，但不会持久化queue里面的数据。

2、发送消息时将消息的deliveryMode设置为2，就是将消息设置为持久化，此时rabbitMq就会将消息持久化到磁盘

必须同时进行这两个数据才可以。   

消费者丢数据：

消费者弄丢数据：

1、消费端开启了autoAck,自动提交，导致消费者可能并未完成消费，就自动提交了消费已经被消费掉的信息

2、解决办法是关闭自动提交，进行手动提交

## 05、如何保证消息的顺序

 Rabbit：

在queue中的数据消费是有序的，所以如果有多个消费者，就为每个消费者创建一个queue，没从达到有序消费的目的。

kafka：

首先kafka的partation的数据肯定是有顺序的，而且一个消费者只能对应一个partation，但kafka一个消费者可能会有多个线程消费，所以就会导致消费的数据无序，这种情况，需要对数据的key进行hash算法，放入到指定的内存队列，比如数据消费顺序是A_info，B_info,C_info。此时需要将数据先分别保存到队列A,B,C中，当线程消费时，就按顺序从A,B,C队列拿到A_info，B_info,C_info数据进行顺序消费。 

## 06、mq挤压了大量的数据

- 由于消费者挂掉，mq挤压大量数据，如果恢复消费者，快速消费挤压数据
- mq积压大量数据，导致mq磁盘满
- rabbitMq 设置过期时间 由于数据太大来不及消费，一些数据过期丢失 如何解决

## 07、如何设计一个消息中间件

## 